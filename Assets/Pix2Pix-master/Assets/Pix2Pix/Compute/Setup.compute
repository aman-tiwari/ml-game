// Kernels for preparation
// https://github.com/keijiro/Pix2Pix

#pragma enable_d3d11_debug_symbols

// The ReorderWeights kernel is used to reorder tensors from [x y z w] order
// to [x y w z] order. This is needed to accelerate the transposed convolution
// layers with enabling coalesced memory access (huge performance boost on
// NVIDIA GPUs). Also the kernel itself is optimized with memory coalescing.

#pragma kernel ReorderWeights THREADS=64

Buffer<float> Input;
RWBuffer<float> Output;

uint4 InputShape;
uint4 OutputShape;
uint4 InputIndexer;
uint4 OutputIndexer;

groupshared float cache[THREADS][THREADS];

[numthreads(THREADS, 1, 1)]
void ReorderWeights(uint2 group_id : SV_GroupID, uint thread_id : SV_GroupThreadID)
{
    const uint2 x_y = group_id.xy;

    for (uint z_base = 0; z_base < InputShape.z; z_base += THREADS)
    {
        for (uint w_base = 0; w_base < InputShape.w; w_base += THREADS)
        {
            uint z, w;

            // Load a THREADS x THREADS block of the input tensor into the
            // cache in a coalesced memory access pattern.
            w = w_base + thread_id;
            if (w < InputShape.w)
                for (z = z_base; z < min(z_base + THREADS, InputShape.z); z++)
                    cache[z - z_base][thread_id] = Input[dot(InputIndexer, uint4(x_y, z, w))];

            GroupMemoryBarrierWithGroupSync();

            // Transpose and store the contents of the cache into the output
            // tensor in a coalesced memory access pattern.
            z = z_base + thread_id;
            if (z < InputShape.z)
                for (w = w_base; w < min(w_base + THREADS, InputShape.w); w++)
                    Output[dot(OutputIndexer, uint4(x_y, w, z))] = cache[thread_id][w - w_base];

            GroupMemoryBarrierWithGroupSync();
        }
    }
}
